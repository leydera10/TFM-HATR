{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1keJJf9fDMU5NSvJk2uCsyRb1HiVue5cm",
      "authorship_tag": "ABX9TyM6wlNMKHan6YHgX6REEQZq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGpJefGZPDfn"
      },
      "outputs": [],
      "source": [
       "# =========================================================\n",
    "# HATR (River) – Ene/Jun/Oct 2018 (SIN ADWIN, SOLO PageHinkley)\n",
    "# Ventanas: 2 meses previos, actualización online, sin fuga de features\n",
    "# Genera: predicciones, métricas, top/bottom, histogramas, paneles y boxplots\n",
    "# =========================================================\n",
    f"# Autor: Leider Javier Asis González  |  País: Colombia\n",
    f"# Email: leider@asisasis30.com\n",
    "# TFM: Predicción de la curva de carga de transformadores de distribución para gestión activa de la demanda\n",
    "# Repositorio: https://github.com/leydera10/TFM-HATR\n",
    "# Licencia: MIT  |  © 2025 Leider Javier Asis González\n",
    "# =========================================================\n",
        "# 0) Instalación versiones compatibles (pandas/river)\n",
        "!pip -q install --force-reinstall --no-deps \"pandas==2.2.2\" \"river==0.21.1\" \"tqdm\" \"joblib\"\n",
        "\n",
        "# 1) Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import timedelta\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from river import preprocessing\n",
        "from river.tree import HoeffdingAdaptiveTreeRegressor\n",
        "from river.drift import PageHinkley     # << ADWIN eliminado\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# 2) Rutas\n",
        "RUTA_DATA = \"/content/drive/MyDrive/Master/TFM2/Normal_data/kaggle_transformadores_imputado_completo.csv\"\n",
        "RUTA_AGRUP = \"/content/drive/MyDrive/Master/TFM2/Agrupación.xlsx\"  # opcional\n",
        "SALIDA_DIR = \"/content/drive/MyDrive/Master/TFM2/hatr_outputs_eval\"\n",
        "os.makedirs(SALIDA_DIR, exist_ok=True)\n",
        "\n",
        "# 3) Configuración\n",
        "MESES = [1, 6, 10]                 # Enero, Junio, Octubre\n",
        "N_JOBS = 8                         # paralelismo\n",
        "PARALLEL_PREFER = \"threads\"        # << usar hilos (no procesos)\n",
        "ROLL_TRAIN_MONTHS = 2              # 2 meses previos\n",
        "\n",
        "# River / HATR\n",
        "PH_DELTA = 0.01\n",
        "GRACE_PERIOD = 300\n",
        "HATR_DELTA = 1e-5\n",
        "\n",
        "# 4) Leer dataset\n",
        "df_all = pd.read_csv(RUTA_DATA, parse_dates=[\"ds\"])\n",
        "df_all = df_all.rename(columns={\"ds\":\"Time\",\"Transformer_ID\":\"group\",\"y\":\"load\"})\n",
        "df_all = df_all.sort_values([\"group\",\"Time\"]).reset_index(drop=True)\n",
        "transformadores = df_all[\"group\"].drop_duplicates().tolist()\n",
        "\n",
        "# 5) Features SIN fuga\n",
        "def preparar_features(df_t, lags=(1,2,3,12,23)):\n",
        "    out = df_t.copy()\n",
        "    out[\"is_weekend\"] = out[\"Time\"].dt.dayofweek.isin([5,6]).astype(int)\n",
        "    out[\"ewma_3\"] = out[\"load\"].ewm(span=3, adjust=False).mean().shift(1)  # << shift(1)\n",
        "    for lag in lags:\n",
        "        out[f\"lag_{lag}\"] = out[\"load\"].shift(lag)\n",
        "    return out.dropna().reset_index(drop=True)\n",
        "\n",
        "FEATURES = [f\"lag_{i}\" for i in (1,2,3,12,23)] + [\"is_weekend\",\"ewma_3\"]\n",
        "\n",
        "def make_pipeline():\n",
        "    return (\n",
        "        preprocessing.StandardScaler() |\n",
        "        HoeffdingAdaptiveTreeRegressor(\n",
        "            grace_period=GRACE_PERIOD,\n",
        "            delta=HATR_DELTA,\n",
        "            leaf_prediction=\"adaptive\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# 6) Núcleo por transformador/mes (solo PageHinkley)\n",
        "def evaluar_mes_para_transformador(df_t, mes):\n",
        "    start_date = pd.Timestamp(f\"2018-{mes:02d}-01 00:00:00\")\n",
        "    end_date   = (start_date + pd.offsets.MonthEnd(0)).replace(hour=23)\n",
        "    all_days   = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
        "\n",
        "    df_t = preparar_features(df_t)\n",
        "    if df_t.empty:\n",
        "        return []\n",
        "\n",
        "    gid = int(df_t[\"group\"].iloc[0])\n",
        "    preds = []\n",
        "\n",
        "    for day in all_days:\n",
        "        train_end   = day - pd.Timedelta(hours=1)\n",
        "        train_start = train_end - pd.DateOffset(months=ROLL_TRAIN_MONTHS)\n",
        "        pred_start  = day\n",
        "        pred_end    = day + pd.Timedelta(hours=23)\n",
        "\n",
        "        train_data = df_t[(df_t[\"Time\"] >= train_start) & (df_t[\"Time\"] <= train_end)]\n",
        "        pred_data  = df_t[(df_t[\"Time\"] >= pred_start)  & (df_t[\"Time\"] <= pred_end)]\n",
        "\n",
        "        if len(train_data) < 100 or len(pred_data) < 24:\n",
        "            continue\n",
        "\n",
        "        model = make_pipeline()\n",
        "        ph = PageHinkley(delta=PH_DELTA)\n",
        "\n",
        "        # fit histórico (NO reasignar)\n",
        "        for _, row in train_data.iterrows():\n",
        "            x = {f: row[f] for f in FEATURES}\n",
        "            y = row[\"load\"]\n",
        "            model.learn_one(x, y)\n",
        "\n",
        "        # predicción 24h + update + drift (solo PH)\n",
        "        for _, row in pred_data.iterrows():\n",
        "            x = {f: row[f] for f in FEATURES}\n",
        "            y = row[\"load\"]\n",
        "            y_pred = model.predict_one(x)\n",
        "            if y_pred is None:\n",
        "                y_pred = 0.0\n",
        "\n",
        "            preds.append({\n",
        "                \"Time\": row[\"Time\"], \"Transformer_ID\": gid,\n",
        "                \"y_real\": y, \"y_pred\": y_pred, \"Mes\": mes\n",
        "            })\n",
        "\n",
        "            model.learn_one(x, y)\n",
        "\n",
        "            if ph.update(y - y_pred):           # drift → reiniciar\n",
        "                model = make_pipeline()\n",
        "                ph = PageHinkley(delta=PH_DELTA)\n",
        "\n",
        "    return preds\n",
        "\n",
        "def correr_mes(mes):\n",
        "    resultados = Parallel(n_jobs=N_JOBS, prefer=PARALLEL_PREFER)(\n",
        "        delayed(evaluar_mes_para_transformador)(\n",
        "            df_all[df_all[\"group\"]==tid].copy(), mes\n",
        "        ) for tid in tqdm(transformadores, desc=f\"Mes {mes}\")\n",
        "    )\n",
        "    df_preds = pd.DataFrame([r for sub in resultados for r in sub])\n",
        "    out_csv = os.path.join(SALIDA_DIR, f\"predicciones_2018_mes{mes}.csv\")\n",
        "    df_preds.to_csv(out_csv, index=False)\n",
        "    print(f\"[OK] Guardado: {out_csv} ({len(df_preds):,} filas)\")\n",
        "    return df_preds\n",
        "\n",
        "# 7) Ejecutar meses\n",
        "preds = []\n",
        "for m in MESES:\n",
        "    preds.append(correr_mes(m))\n",
        "df_preds = pd.concat(preds, ignore_index=True)\n",
        "\n",
        "# 8) Métricas por TX y Mes\n",
        "def mape(y_true, y_pred, eps=1e-9):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mask = np.abs(y_true) > eps\n",
        "    if mask.sum()==0:\n",
        "        return np.nan\n",
        "    return np.mean(np.abs((y_true[mask]-y_pred[mask]) / y_true[mask]))*100\n",
        "\n",
        "metricas = []\n",
        "for (tx, mes), g in df_preds.groupby([\"Transformer_ID\",\"Mes\"]):\n",
        "    y, yhat = g[\"y_real\"].values, g[\"y_pred\"].values\n",
        "    mae = mean_absolute_error(y, yhat)\n",
        "    mp  = mape(y, yhat)\n",
        "    try:\n",
        "        r2 = r2_score(y, yhat)\n",
        "    except Exception:\n",
        "        r2 = np.nan\n",
        "    metricas.append({\"Transformer_ID\":tx,\"Mes\":mes,\"MAE_\":mae,\"MAPE_\":mp,\"R2\":r2})\n",
        "\n",
        "df_metricas_tx_mes = pd.DataFrame(metricas).sort_values([\"Mes\",\"R2\"], ascending=[True, False])\n",
        "out_metricas_csv = os.path.join(SALIDA_DIR, \"metricas_por_tx_y_mes.csv\")\n",
        "df_metricas_tx_mes.to_csv(out_metricas_csv, index=False)\n",
        "print(f\"[OK] Guardado: {out_metricas_csv}\")\n",
        "\n",
        "# 9) Top/Bottom 10 por mes\n",
        "top_list, bottom_list = [], []\n",
        "nombre_mes = {1:\"enero\",6:\"junio\",10:\"octubre\"}\n",
        "\n",
        "for m in MESES:\n",
        "    dfm = df_metricas_tx_mes[df_metricas_tx_mes[\"Mes\"]==m].copy()\n",
        "    if dfm.empty: continue\n",
        "    dfm[\"rank_score\"] = dfm[\"R2\"].rank(ascending=False, method=\"min\") + \\\n",
        "                        dfm[\"MAPE_\"].rank(ascending=True,  method=\"min\")\n",
        "    top_list.append(dfm.nsmallest(10, \"rank_score\").assign(MesNombre=nombre_mes[m]))\n",
        "    dfm[\"rank_score_bad\"] = dfm[\"R2\"].rank(ascending=True,  method=\"min\") + \\\n",
        "                            dfm[\"MAPE_\"].rank(ascending=False, method=\"min\")\n",
        "    bottom_list.append(dfm.nlargest(10, \"rank_score_bad\").assign(MesNombre=nombre_mes[m]))\n",
        "\n",
        "top10 = pd.concat(top_list, ignore_index=True)\n",
        "bot10 = pd.concat(bottom_list, ignore_index=True)\n",
        "\n",
        "top_csv = os.path.join(SALIDA_DIR, \"top10_por_mes.csv\")\n",
        "bot_csv = os.path.join(SALIDA_DIR, \"bottom10_por_mes.csv\")\n",
        "top10.to_csv(top_csv, index=False)\n",
        "bot10.to_csv(bot_csv, index=False)\n",
        "print(f\"[OK] Guardados TOP/BOTTOM:\\n  {top_csv}\\n  {bot_csv}\")\n",
        "\n",
        "# 10) Resumen por variabilidad (opcional)\n",
        "try:\n",
        "    df_agr = pd.read_excel(RUTA_AGRUP)\n",
        "    df_agr[\"Variabilidad\"] = df_agr[\"Variabilidad\"].astype(str).str.extract(r'(Baja|Media|Alta)', expand=False)\n",
        "    du = df_metricas_tx_mes.merge(df_agr[[\"Transformer_ID\",\"Variabilidad\"]],\n",
        "                                  on=\"Transformer_ID\", how=\"left\")\n",
        "    resumen = (du.groupby([\"Mes\",\"Variabilidad\"])[[\"MAE_\",\"MAPE_\",\"R2\"]]\n",
        "               .mean().reset_index())\n",
        "    resumen_csv = os.path.join(SALIDA_DIR, \"resumen_por_mes_y_variabilidad.csv\")\n",
        "    resumen.to_csv(resumen_csv, index=False)\n",
        "    print(f\"[OK] Guardado: {resumen_csv}\")\n",
        "except Exception as e:\n",
        "    print(\"[AVISO] No se generó resumen por variabilidad:\", e)\n",
        "\n",
        "# 11) Gráficas – histogramas R²\n",
        "for m in MESES:\n",
        "    sub = df_metricas_tx_mes[df_metricas_tx_mes[\"Mes\"]==m][\"R2\"].dropna()\n",
        "    if sub.empty: continue\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.hist(sub, bins=20)\n",
        "    plt.title(f'Histograma de R² – Mes {m}')\n",
        "    plt.xlabel('R²'); plt.ylabel('Frecuencia')\n",
        "    path = os.path.join(SALIDA_DIR, f\"hist_r2_mes{m}.png\")\n",
        "    plt.savefig(path, dpi=160, bbox_inches='tight'); plt.close()\n",
        "    print(\"Guardado:\", path)\n",
        "\n",
        "# 12) Paneles 2×2 (Good/Medium/Bad/Outliers) para R2/MAE_/MAPE_\n",
        "def thr_outlier_iqr(vals, mayor_es_mejor):\n",
        "    vals = vals[~np.isnan(vals)]\n",
        "    if len(vals)==0: return None\n",
        "    q1, q3 = np.nanpercentile(vals, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    return (q1 - 1.5*iqr) if mayor_es_mejor else (q3 + 1.5*iqr)\n",
        "\n",
        "def particiona(dfm, metric, mayor_es_mejor, thr_good, thr_med, thr_out):\n",
        "    x = dfm[metric].values\n",
        "    if mayor_es_mejor:\n",
        "        good = dfm[x >= thr_good]\n",
        "        med  = dfm[(x < thr_good) & (x >= thr_med)]\n",
        "        bad  = dfm[(x < thr_med)  & (x >= thr_out)]\n",
        "        out  = dfm[x < thr_out]\n",
        "    else:\n",
        "        good = dfm[x <= thr_good]\n",
        "        med  = dfm[(x > thr_good) & (x <= thr_med)]\n",
        "        bad  = dfm[(x > thr_med)  & (x <= thr_out)]\n",
        "        out  = dfm[x > thr_out]\n",
        "    return {'good':good, 'med':med, 'bad':bad, 'out':out}\n",
        "\n",
        "def plot_panel(dfm, metric, mayor_es_mejor, thr_good, thr_med, titulo, savepath):\n",
        "    thr_out = thr_outlier_iqr(dfm[metric].to_numpy(), mayor_es_mejor)\n",
        "    if thr_out is None:\n",
        "        thr_out = (dfm[metric].min()-1.0) if mayor_es_mejor else (dfm[metric].max()+1.0)\n",
        "    if mayor_es_mejor:\n",
        "        thr_out = min(thr_out, thr_med-1e-9)\n",
        "    else:\n",
        "        thr_out = max(thr_out, thr_med+1e-9)\n",
        "\n",
        "    parts = particiona(dfm, metric, mayor_es_mejor, thr_good, thr_med, thr_out)\n",
        "\n",
        "    fig, axes = plt.subplots(2,2, figsize=(12,8))\n",
        "    fig.suptitle(f'{metric} – {titulo}', fontsize=14)\n",
        "    for ax, (k, subt) in zip(axes.ravel(),\n",
        "                             [('good','Good'),('med','Medium'),('bad','Bad'),('out','Outliers')]):\n",
        "        sub = parts[k].sort_values('Transformer_ID')\n",
        "        ax.plot(sub['Transformer_ID'], sub[metric], marker='o', linestyle='-')\n",
        "        ax.set_title(subt); ax.set_xlabel('Transformer ID'); ax.set_ylabel(metric)\n",
        "        if mayor_es_mejor:\n",
        "            ax.axhline(thr_med,  color='gold',  linestyle='--', label=f'{metric}={thr_med:g}')\n",
        "            ax.axhline(thr_good, color='black', linestyle='--', label=f'{metric}={thr_good:g}')\n",
        "            ax.axhline(thr_out,  color='red',   linestyle='--', label=f'out≈{thr_out:.2g}')\n",
        "        else:\n",
        "            ax.axhline(thr_good, color='black', linestyle='--', label=f'good≤{thr_good:g}')\n",
        "            ax.axhline(thr_med,  color='gold',  linestyle='--', label=f'med≤{thr_med:g}')\n",
        "            ax.axhline(thr_out,  color='red',   linestyle='--', label=f'out≈{thr_out:.2g}')\n",
        "        ax.legend(loc='lower right', fontsize=8)\n",
        "\n",
        "    plt.tight_layout(rect=[0,0,1,0.96])\n",
        "    plt.savefig(savepath, dpi=160, bbox_inches='tight'); plt.close()\n",
        "    print(\"Guardado:\", savepath)\n",
        "\n",
        "metricas_panel = [\n",
        "    ('R2',    True,  0.80, 0.50),\n",
        "    ('MAPE_', False, 5.00, 10.0),\n",
        "    ('MAE_',  False, 0.20, 0.80),\n",
        "]\n",
        "nombre_mes = {1:'Enero', 6:'Junio', 10:'Octubre'}\n",
        "\n",
        "for m in MESES:\n",
        "    dfm = df_metricas_tx_mes[df_metricas_tx_mes['Mes']==m].copy()\n",
        "    if dfm.empty: continue\n",
        "    for metric, mayor_es_mejor, thr_good, thr_med in metricas_panel:\n",
        "        sp = os.path.join(SALIDA_DIR, f'panel_{metric}_mes{m}.png')\n",
        "        plot_panel(dfm, metric, mayor_es_mejor, thr_good, thr_med,\n",
        "                   f\"{nombre_mes[m]} (Mes {m})\", sp)\n",
        "\n",
        "# 13) Boxplots por variabilidad + Scatter (si hay Excel)\n",
        "try:\n",
        "    df_agr = pd.read_excel(RUTA_AGRUP)\n",
        "    df_agr[\"Variabilidad\"] = df_agr[\"Variabilidad\"].astype(str).str.extract(r'(Baja|Media|Alta)', expand=False)\n",
        "    du = df_metricas_tx_mes.merge(df_agr[[\"Transformer_ID\",\"Variabilidad\"]],\n",
        "                                  on=\"Transformer_ID\", how=\"left\")\n",
        "    for metric in [\"R2\",\"MAPE_\",\"MAE_\"]:\n",
        "        plt.figure(figsize=(6,4))\n",
        "        data = [du[du[\"Variabilidad\"]==v][metric].dropna() for v in [\"Alta\",\"Baja\",\"Media\"] if v in du[\"Variabilidad\"].unique()]\n",
        "        labels = [v for v in [\"Alta\",\"Baja\",\"Media\"] if v in du[\"Variabilidad\"].unique()]\n",
        "        plt.boxplot(data, tick_labels=labels, showmeans=True)\n",
        "        plt.title(f'Distribución de {metric} por variabilidad'); plt.ylabel(metric)\n",
        "        path = os.path.join(SALIDA_DIR, f'boxplot_{metric}_por_variabilidad.png')\n",
        "        plt.savefig(path, dpi=160, bbox_inches='tight'); plt.close()\n",
        "        print(\"Guardado:\", path)\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    for v in du[\"Variabilidad\"].dropna().unique():\n",
        "        sub = du[du[\"Variabilidad\"]==v]\n",
        "        plt.scatter(sub[\"MAPE_\"], sub[\"R2\"], s=18, label=v, alpha=0.8)\n",
        "    plt.xlabel(\"MAPE\"); plt.ylabel(\"R²\"); plt.legend()\n",
        "    path = os.path.join(SALIDA_DIR, 'scatter_mape_vs_r2.png')\n",
        "    plt.savefig(path, dpi=160, bbox_inches='tight'); plt.close()\n",
        "    print(\"Guardado:\", path)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"[AVISO] Boxplots/Scatter no generados:\", e)\n",
        "\n",
        "print(\"\\n Listo. Revisa todos los archivos en:\", SALIDA_DIR)\n"
      ]
    }
  ]
}
